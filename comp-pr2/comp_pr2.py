# -*- coding: utf-8 -*-
"""comp-pr2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1T7tlS4kqwtRVnj9qA3LfsJSU5YVC4__v
"""

# Імпорт необхідних бібліотек
import pandas as pd

# Крок 1: Створення фрейму даних
# (а) Імпорт csv-файлу
training = pd.read_csv("titanic-train.csv")

# (б) Перевірка імпорту і перегляд даних
print("Інформація про дані:")
training.info()

# Перевірка кількості відсутніх значень
print("\nКількість відсутніх значень у кожному стовпці:")
print(training.isnull().sum())

# Перегляд перших рядків
print("\nПерші 5 рядків набору даних:")
print(training.head())

# Крок 2: Підготовка даних
# (а) Замінюємо текстову стать на числову
training["Gender"] = training["Gender"].apply(lambda toLabel: 0 if toLabel == 'male' else 1)

# (б) Перевірка, що заміна пройшла успішно
print("\nЗначення Gender після перетворення:")
print(training[["Gender"]].head())

# (в) Заповнення відсутніх значень у віці середнім значенням
mean_age = training["Age"].mean()
training["Age"].fillna(mean_age, inplace=True)

# (г) Перевірка, що значення були замінені
print("\nПеревірка, що відсутні значення у 'Age' відсутні:")
print(training["Age"].isnull().sum())

print(f"\nСереднє значення віку, яке було використано для заміни: {mean_age:.2f}")

# Крок 3. Навчання і оцінювання моделі класифікатора дерева рішень

# а) Створення цільової змінної (ціль - виживання пасажира: 1 - вижив, 0 - ні)
y_target = training["Survived"].values

# б) Формування вхідних ознак, які будуть використані для навчання моделі
# Обираємо релевантні колонки для навчання
columns = ["Fare", "Pclass", "Gender", "Age", "SibSp"]
X_input = training[list(columns)].values

# в) Імпортуємо модуль дерева рішень зі sklearn та створюємо об'єкт моделі
from sklearn import tree
# Створюємо об'єкт класифікатора з критерієм "entropy" та обмеженням глибини дерева
clf_train = tree.DecisionTreeClassifier(criterion="entropy", max_depth=3)

# Навчаємо модель на основі вхідних даних X_input та цільових y_target
clf_train = clf_train.fit(X_input, y_target)

# г) Оцінюємо точність моделі на тренувальному наборі
accuracy = clf_train.score(X_input, y_target)

# Виводимо результат точності (відсоткове значення)
print("Точність класифікації на тренувальних даних:", round(accuracy * 100, 2), "%")

# Крок 4. Візуалізуємо дерево рішень

# а) Створення проміжного .dot файлу для подальшої візуалізації
from sklearn.tree import export_graphviz
with open("titanic.dot", 'w') as f:
  f = tree.export_graphviz(clf_train, out_file=f, feature_names=columns)

# б) Встановлення Graphviz
# !apt-get install graphviz

# в) Перетворення .dot файлу у .png за допомогою команди оболонки
!dot -Tpng titanic.dot -o titanic.png

# г) Відображення графічного зображення дерева рішень
from IPython.display import Image

Image("titanic.png")

# Крок 5. Імпортуємо та підготуємо дані

# а) Імпортуємо дані
# Імпортуємо файл titanic-test.csv у фрейм даних "testing"
testing = pd.read_csv("titanic-test.csv")

# Перевіримо скільки записів у наборі даних
print("Кількість записів у наборі даних:", testing.shape[0])

# Яких важливих змінних значень немає, скільки відсутніх?
print("Пропущені значення у наборі даних:")
print(testing.isnull().sum())

# б) Використовуємо лямбда-вираз, щоб замінити значення "male" та "female" на 0 для чоловіків і 1 для жінок
testing["Gender"] = testing["Gender"].apply(lambda x: 0 if x == "male" else 1)

# в) Заміняємо пропущені значення віку на середнє значення віку
testing["Age"].fillna(testing["Age"].mean(), inplace=True)

# г) Переконайтесь, що значення були замінені
# Перевіряємо відсутні значення
print("Перевірка на відсутні значення після заміни:")
print(testing.isnull().sum())

# Перевіримо перші кілька рядків, щоб упевнитися в правильності замін
print("Перші 5 записів у фреймі даних:")
print(testing.head())

# Крок 6. Позначте набір даних тестування.

# а) Створіть масив вхідних змінних із набору даних тестування.
# Створюємо змінну X_input, яка містить вхідні ознаки для класифікатора.
X_input = testing[list(columns)].values

# б) Застосуйте модель до набору даних тестування.
# Використовуємо метод predict() для передбачення виживання пасажирів на основі тестових даних.
target_labels = clf_train.predict(X_input)

# Перетворюємо результат у формат DataFrame для зручності аналізу.
target_labels = pd.DataFrame({'Est_Survival': target_labels, 'Name': testing['Name']})

# Виводимо перші кілька рядків отриманого набору даних для перевірки.
target_labels.head()

# в) Оцініть точність передбачуваних міток.
# Для оцінки точності порівнюємо передбачення з реальними значеннями виживання з іншого набору даних all_data.csv.
import numpy as np

# Завантажуємо дані для всіх пасажирів із файлу all_data.csv.
all_data = pd.read_csv("titanic_all.csv")

# Об'єднуємо обидва набори даних по полю 'Name', щоб порівняти реальні і передбачувані мітки.
testing_results = pd.merge(target_labels, all_data[['Name', 'Survived']], on=['Name'])

# Обчислюємо точність моделі як відношення правильних передбачень до загальної кількості спостережень.
acc = np.sum(testing_results['Est_Survival'] == testing_results['Survived']) / float(len(testing_results))

print(f"Точність моделі на тестових даних: {acc:.4f}")

# Крок 7. Імпортуємо дані з файлу CSV, вказуючи необхідні стовпці.
# Для цього передаємо список імен стовпців у параметр usecols методу read_csv()

# Імпортуємо дані з файлу titanic_all.csv, використовуючи тільки вказані стовпці
all_data = pd.read_csv("titanic_all.csv", usecols=['Survived', 'Pclass', 'Gender', 'Age', 'SibSp', 'Fare'])

all_data.info()

# Підрахуємо кількість записів у наборі даних
total_records = all_data.shape[0]

# Підрахуємо кількість відсутніх значень для кожного стовпця
missing_values = all_data.isnull().sum()

# Загальна кількість відсутніх значень
total_missing = missing_values.sum()

print(f"Кількість записів у наборі даних: {total_records}")
print("Пропущені значення у наборі даних:")
print(missing_values)
print(f"Загальна кількість відсутніх значень: {total_missing}")

# Крок 8. Підготовка даних.

# a) Видалення значень "male" і "female" у стовпці Gender, заміна на 0 і 1 відповідно
all_data['Gender'] = all_data['Gender'].replace({'male': 0, 'female': 1})

# b) Заміняємо пропущені значення віку на середнє значення віку всіх пасажирів
mean_age = all_data['Age'].mean()  # Обчислюємо середній вік
all_data['Age'].fillna(mean_age, inplace=True)  # Заміняємо пропущені значення на середнє

print(all_data.head())

# Крок 9. Створення вхідних та вихідних змінних, навчання моделі та оцінка

# a) Імпортуємо необхідну функцію train_test_split з бібліотеки sklearn.model_selection
from sklearn.model_selection import train_test_split

# b) Створюємо вхідні (X) та цільову (y) змінні. Використовуємо список стовпців з попередніх кроків
columns = ['Pclass', 'Gender', 'Age', 'SibSp', 'Fare']
X = all_data[columns].values  # Вхідні змінні
y = all_data['Survived'].values  # Цільова змінна

# c) Розділяємо набір даних на тренувальний і тестовий (40% для тестування, фіксуємо random_state)
X_train,X_test,y_train,y_test = train_test_split(X, y, test_size=0.40, random_state=0)

# d) Створюємо класифікатор дерева рішень з критерієм "entropy" та глибиною 3
from sklearn import tree
clf_train = tree.DecisionTreeClassifier(criterion="entropy", max_depth=3)

# e) Навчаємо модель на тренувальних даних
clf_train = clf_train.fit(X_train, y_train)

# f) Обчислюємо точність моделі на тренувальних і тестових даних
train_score = str(clf_train.score(X_train, y_train))
test_score = str(clf_train.score(X_test, y_test))

# g) Виводимо результати
print('Training score = ' + train_score + ' Testing score = ' + test_score)